{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4952fd5f-d4a6-47a1-9de7-87bf4ad35cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e7769c-43f2-44c5-8744-fd3db5e08bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c72e36-8ee8-4a4a-80f1-24565609654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not just single words but doc and spans of docs also have vector embeddings.\n",
    "    \n",
    "    nlp(u'<text>').vector <-- returns a 300 dimensional vector\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b401e2e5-0ffc-47bb-99af-88feb6e7f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_vector = nlp(u'This').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75d35de-451c-47f2-bc9d-8a5e4ba32c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vector = nlp(u\"\"\"\n",
    "    This is so cool. \n",
    "    How are they creating vectors for such long sentences?\n",
    "    I wish to understand what is going on inside but I want to learn\n",
    "    how to implement them first\n",
    "    \"\"\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b8f8025-b9d3-4aea-8f28-3df6a24fd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'lion cat tiger dog pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21270724-880c-49ac-be69-4b2cca150aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| lion       lion       1.0\n",
      "| lion       cat        0.3854507803916931\n",
      "| lion       tiger      0.713609516620636\n",
      "| lion       dog        0.29493075609207153\n",
      "| lion       pet        0.20031584799289703\n",
      "-----------------------------------------\n",
      "| cat        lion       0.3854507803916931\n",
      "| cat        cat        1.0\n",
      "| cat        tiger      0.5670855045318604\n",
      "| cat        dog        0.8220816850662231\n",
      "| cat        pet        0.732966423034668\n",
      "-----------------------------------------\n",
      "| tiger      lion       0.713609516620636\n",
      "| tiger      cat        0.5670855045318604\n",
      "| tiger      tiger      1.0\n",
      "| tiger      dog        0.42287227511405945\n",
      "| tiger      pet        0.31030499935150146\n",
      "-----------------------------------------\n",
      "| dog        lion       0.29493075609207153\n",
      "| dog        cat        0.8220816850662231\n",
      "| dog        tiger      0.42287227511405945\n",
      "| dog        dog        1.0\n",
      "| dog        pet        0.7856058478355408\n",
      "-----------------------------------------\n",
      "| pet        lion       0.20031584799289703\n",
      "| pet        cat        0.732966423034668\n",
      "| pet        tiger      0.31030499935150146\n",
      "| pet        dog        0.7856058478355408\n",
      "| pet        pet        1.0\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "token1.similarity(token2) --> takes cosine similarity between the vector for token1 & token2\n",
    "\"\"\"\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(f\"| {token1.text:{10}} {token2.text:{10}} {token1.similarity(token2)}\")\n",
    "    print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef7c6530-12c0-4987-853b-4d405d677abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u\"like love hate kill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9771506-a675-4549-ab28-bd4f333c5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similarity(doc):\n",
    "    for token1 in doc:\n",
    "        for token2 in doc:\n",
    "            print(f\"| {token1.text:{10}} {token2.text:{10}} {token1.similarity(token2)}\")\n",
    "        print('-----------------------------------------')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdbbcc9f-5be8-4cb0-baf3-e19a0b799a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| like       like       1.0\n",
      "| like       love       0.5212638974189758\n",
      "| like       hate       0.5065140724182129\n",
      "| like       kill       0.30623432993888855\n",
      "-----------------------------------------\n",
      "| love       like       0.5212638974189758\n",
      "| love       love       1.0\n",
      "| love       hate       0.5708349943161011\n",
      "| love       kill       0.25415143370628357\n",
      "-----------------------------------------\n",
      "| hate       like       0.5065140724182129\n",
      "| hate       love       0.5708349943161011\n",
      "| hate       hate       1.0\n",
      "| hate       kill       0.3746185302734375\n",
      "-----------------------------------------\n",
      "| kill       like       0.30623432993888855\n",
      "| kill       love       0.25415143370628357\n",
      "| kill       hate       0.3746185302734375\n",
      "| kill       kill       1.0\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "show_similarity(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cdb2bdf-aa98-47ab-8693-27fe58b78399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514157, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape # 514157 many unique words with 300 dimension representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d816f573-719a-4413-9916-546aedcff4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNot every word will have an interpretation or will be in the vocab of dictionary\\n\\n    vector_norm --> L2 norm or eucledian distance\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Not every word will have an interpretation or will be in the vocab of dictionary\n",
    "\n",
    "    vector_norm --> L2 norm or eucledian distance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abd36577-f845-44be-b27d-7e9a08d1b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u\"dog cat nargle Abhijeet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99950680-8db4-4577-9df5-aac5e1dd2a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 75.254234 False\n",
      "cat True 63.188496 False\n",
      "nargle False 0.0 True\n",
      "Abhijeet True 17.454887 False\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov) # oov --> out of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60047501-aec0-4988-b718-d256df90ce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nToken arithmatic\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Token arithmatic\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9325d634-3a0b-4889-95ab-8cc7d6681907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c42a5cf-7c99-4752-8429-a1a549242801",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90e8d69f-9e52-4397-9902-0658dc8816d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab['king'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5386ed3e-5596-4d08-9c17-54c7b30daba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "man = nlp.vocab['man'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d4bda09-f8a3-4d1f-9711-ac5d5ecd9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "woman = nlp.vocab['woman'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f10e1f-9d8d-4760-acc8-7e34df3c4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# king - man + woman --> queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0900be53-338e-46f4-9e55-5604cf28091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king-man+woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dbc805f-6c68-4779-9390-9fe5633c4838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "computed_similarites = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(word.vector, new_vector)\n",
    "                computed_similarites.append((word.text, similarity))\n",
    "print(len(computed_similarites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f5ab818-ea46-4830-bc1d-9420ecfa84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarites = sorted(computed_similarites, key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a3210fc-e2a3-4fae-be15-0d8e7a158289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8489541411399841),\n",
       " ('queen', 0.6178014278411865),\n",
       " ('and', 0.3899005055427551),\n",
       " ('that', 0.38483577966690063),\n",
       " ('creating', 0.3748939335346222),\n",
       " ('where', 0.3385923206806183),\n",
       " ('them', 0.33383065462112427),\n",
       " ('she', 0.32445624470710754),\n",
       " ('they', 0.3206636309623718),\n",
       " ('implement', 0.31726282835006714)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_similarites[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10eb7b7-7000-473a-bcab-3b834beb3f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
